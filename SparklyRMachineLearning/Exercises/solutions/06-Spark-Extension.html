<p>This is only a concept script, it runs correctly but is intended for teaching not direct use in production.</p>
<p>One point in particular is this script assumes none of the following directories are present (as it is going to try to create them and write its own temp results):</p>
<ul class="incremental">
<li>Exercises/solutions/df*_tmp</li>
<li>Exercises/solutions/tmpFile*_*</li>
</ul>
<p>We don't delete these as we don't want to perform too many (potentially unsafe) file operations on the user's behalf.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Sys.setenv</span>(<span class="dt">TZ=</span><span class="st">&#39;UTC&#39;</span>)
<span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(<span class="st">&quot;sparklyr&quot;</span>))
<span class="kw">packageVersion</span>(<span class="st">&quot;sparklyr&quot;</span>)</code></pre></div>
<pre><code>## [1] &#39;0.6.3&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>))
<span class="kw">packageVersion</span>(<span class="st">&quot;dplyr&quot;</span>)</code></pre></div>
<pre><code>## [1] &#39;0.7.4&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)</code></pre></div>
<pre><code>## * Using Spark: 2.2.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">20100101120101</span>, <span class="st">&quot;2009-01-02 12-01-02&quot;</span>, <span class="st">&quot;2009.01.03 12:01:03&quot;</span>,
       <span class="st">&quot;2009-1-4 12-1-4&quot;</span>,
       <span class="st">&quot;2009-1, 5 12:1, 5&quot;</span>,
       <span class="st">&quot;200901-08 1201-08&quot;</span>,
       <span class="st">&quot;2009 arbitrary 1 non-decimal 6 chars 12 in between 1 !!! 6&quot;</span>,
       <span class="st">&quot;OR collapsed formats: 20090107 120107 (as long as prefixed with zeros)&quot;</span>,
       <span class="st">&quot;Automatic wday, Thu, detection, 10-01-10 10:01:10 and p format: AM&quot;</span>,
       <span class="st">&quot;Created on 10-01-11 at 10:01:11 PM&quot;</span>))

df  &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, d, <span class="st">&#39;df&#39;</span>, 
               <span class="dt">temporary =</span> <span class="ot">TRUE</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(df)</code></pre></div>
<pre><code>## # Source:   table&lt;df&gt; [?? x 1]
## # Database: spark_connection
##                                                                         x
##                                                                     &lt;chr&gt;
##  1                                                         20100101120101
##  2                                                    2009-01-02 12-01-02
##  3                                                    2009.01.03 12:01:03
##  4                                                        2009-1-4 12-1-4
##  5                                                      2009-1, 5 12:1, 5
##  6                                                      200901-08 1201-08
##  7             2009 arbitrary 1 non-decimal 6 chars 12 in between 1 !!! 6
##  8 OR collapsed formats: 20090107 120107 (as long as prefixed with zeros)
##  9     Automatic wday, Thu, detection, 10-01-10 10:01:10 and p format: AM
## 10                                     Created on 10-01-11 at 10:01:11 PM
## # ... with more rows</code></pre>
<p>Running <code>SQL</code> directly (see <a href="http://spark.rstudio.com" class="uri">http://spark.rstudio.com</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;DBI&quot;</span>)

<span class="co"># returns a in-memor data.frame</span>
dfx &lt;-<span class="st"> </span><span class="kw">dbGetQuery</span>(sc, <span class="st">&quot;SELECT * FROM df LIMIT 5&quot;</span>)
dfx</code></pre></div>
<pre><code>##                     x
## 1      20100101120101
## 2 2009-01-02 12-01-02
## 3 2009.01.03 12:01:03
## 4     2009-1-4 12-1-4
## 5   2009-1, 5 12:1, 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># build another table</span>
<span class="kw">dbSendQuery</span>(sc, <span class="st">&quot;CREATE TABLE df2 AS SELECT * FROM df LIMIT 5&quot;</span>)</code></pre></div>
<pre><code>## &lt;DBISparkResult&gt;
##   SQL  CREATE TABLE df2 AS SELECT * FROM df LIMIT 5
##   ROWS Fetched: 0 [complete]
##        Changed: 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get a handle to it</span>
<span class="kw">dbListTables</span>(sc)</code></pre></div>
<pre><code>## [1] &quot;df&quot;  &quot;df2&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df2 &lt;-<span class="st"> </span>dplyr::<span class="kw">tbl</span>(sc, <span class="st">&#39;df2&#39;</span>)
df2</code></pre></div>
<pre><code>## # Source:   table&lt;df2&gt; [?? x 1]
## # Database: spark_connection
##                     x
##                 &lt;chr&gt;
## 1      20100101120101
## 2 2009-01-02 12-01-02
## 3 2009.01.03 12:01:03
## 4     2009-1-4 12-1-4
## 5   2009-1, 5 12:1, 5</code></pre>
<p>Using <code>SparkR</code> for <code>R</code> user defined functions. Replaced by <a href="https://spark.rstudio.com/articles/guides-distributed-r.html"><code>sparklyr::spark_apply()</code></a> (<a href="https://github.com/rstudio/sparklyr/blob/master/NEWS.md">wasn't available until Sparklyr 0.6.0</a>, <a href="https://cran.rstudio.com/src/contrib/Archive/sparklyr/">released to CRAN 29-Jul-2017</a>).</p>
<p>The following doesn't always run in a knitr evironment. And using <code>SparkR</code> in production would entail already having the needed R packages installed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dMany  &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, <span class="kw">bind_rows</span>(<span class="kw">rep</span>(<span class="kw">list</span>(d), <span class="dv">100000</span>)), <span class="st">&#39;dMany&#39;</span>, 
                  <span class="dt">temporary =</span> <span class="ot">TRUE</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
f &lt;-<span class="st"> </span>function(df, ...) {
  df$cleaned =<span class="st"> </span><span class="kw">as.character</span>(lubridate::<span class="kw">ymd_hms</span>(df$x))
  df$nrow &lt;-<span class="st"> </span><span class="kw">nrow</span>(df)
  df$clsstr &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">class</span>(df), <span class="dt">collapse =</span> <span class="st">&#39; &#39;</span>)
  df
}
dfR &lt;-<span class="st"> </span><span class="kw">spark_apply</span>(dMany, f, 
                   <span class="dt">columns =</span> <span class="kw">c</span>(<span class="kw">colnames</span>(dMany), <span class="st">&#39;cleaned&#39;</span>, <span class="st">&#39;nrow&#39;</span>, <span class="st">&#39;clsstr&#39;</span>))
replyr::<span class="kw">replyr_nrow</span>(dMany)</code></pre></div>
<pre><code>## [1] 1e+06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">replyr::<span class="kw">replyr_nrow</span>(dfR)</code></pre></div>
<pre><code>## [1] 1e+06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(dfR)</code></pre></div>
<pre><code>## [1] &quot;tbl_spark&quot; &quot;tbl_sql&quot;   &quot;tbl_lazy&quot;  &quot;tbl&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(dfR)</code></pre></div>
<pre><code>## Observations: 25
## Variables: 4
## $ x       &lt;chr&gt; &quot;20100101120101&quot;, &quot;2009-01-02 12-01-02&quot;, &quot;2009.01.03 1...
## $ cleaned &lt;chr&gt; &quot;2010-01-01 12:01:01&quot;, &quot;2009-01-02 12:01:02&quot;, &quot;2009-01...
## $ nrow    &lt;int&gt; 279209, 279209, 279209, 279209, 279209, 279209, 279209...
## $ clsstr  &lt;chr&gt; &quot;data.frame&quot;, &quot;data.frame&quot;, &quot;data.frame&quot;, &quot;data.frame&quot;...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(dfR)</code></pre></div>
<pre><code>## # Source:   table&lt;sparklyr_tmp_132ae2a7a8429&gt; [?? x 4]
## # Database: spark_connection
##                                                                         x
##                                                                     &lt;chr&gt;
##  1                                                         20100101120101
##  2                                                    2009-01-02 12-01-02
##  3                                                    2009.01.03 12:01:03
##  4                                                        2009-1-4 12-1-4
##  5                                                      2009-1, 5 12:1, 5
##  6                                                      200901-08 1201-08
##  7             2009 arbitrary 1 non-decimal 6 chars 12 in between 1 !!! 6
##  8 OR collapsed formats: 20090107 120107 (as long as prefixed with zeros)
##  9     Automatic wday, Thu, detection, 10-01-10 10:01:10 and p format: AM
## 10                                     Created on 10-01-11 at 10:01:11 PM
## # ... with more rows, and 3 more variables: cleaned &lt;chr&gt;, nrow &lt;int&gt;,
## #   clsstr &lt;chr&gt;</code></pre>
<p>From: <a href="http://spark.rstudio.com/extensions.html" class="uri">http://spark.rstudio.com/extensions.html</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">count_lines &lt;-<span class="st"> </span>function(sc, file) {
  <span class="kw">spark_context</span>(sc) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">invoke</span>(<span class="st">&quot;textFile&quot;</span>, file, 1L) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">invoke</span>(<span class="st">&quot;count&quot;</span>)
}

<span class="kw">count_lines</span>(sc, <span class="st">&quot;tmp.csv&quot;</span>)</code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>A simple Java example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">billionBigInteger &lt;-<span class="st"> </span><span class="kw">invoke_new</span>(sc, <span class="st">&quot;java.math.BigInteger&quot;</span>, <span class="st">&quot;1000000000&quot;</span>)
<span class="kw">print</span>(billionBigInteger)</code></pre></div>
<pre><code>## &lt;jobj[175]&gt;
##   class java.math.BigInteger
##   1000000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(billionBigInteger)</code></pre></div>
<pre><code>## Classes &#39;spark_jobj&#39;, &#39;shell_jobj&#39; &lt;environment: 0x7fe678dfa068&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">billion &lt;-<span class="st"> </span><span class="kw">invoke</span>(billionBigInteger, <span class="st">&quot;longValue&quot;</span>)
<span class="kw">str</span>(billion)</code></pre></div>
<pre><code>##  num 1e+09</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">spark_disconnect</span>(sc)</code></pre></div>
